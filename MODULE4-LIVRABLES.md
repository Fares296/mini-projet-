# MODULE 4 - LIVRABLES
## ScalabilitÃ© Horizontale & Load Balancing

---

## âœ… RÃ‰SUMÃ‰ DES TRAVAUX RÃ‰ALISÃ‰S

### Vue d'ensemble

Le Module 4 implÃ©mente la **scalabilitÃ© horizontale** en dÃ©ployant **3 instances** du microservice `users-service` avec un **load balancing** automatique via NGINX. Cela dÃ©montre la capacitÃ© de l'architecture Ã  gÃ©rer une charge accrue en ajoutant des instances supplÃ©mentaires.

---

## ğŸš€ 1. LANCEMENT DE 3 INSTANCES USERS-SERVICE âœ…

### Configuration Docker Compose

**Fichier**: `docker-compose.yml`

#### Instances dÃ©ployÃ©es

```yaml
users-service-1:
  container_name: users-service-1
  hostname: users-service-1
  ports: "3000:3000"
  INSTANCE_ID: "1"

users-service-2:
  container_name: users-service-2
  hostname: users-service-2
  ports: "3004:3000"  
  INSTANCE_ID: "2"

users-service-3:
  container_name: users-service-3
  hostname: users-service-3
  ports: "3003:3000"
  INSTANCE_ID: "3"
```

**CaractÃ©ristiques** :
- âœ… **3 conteneurs indÃ©pendants** basÃ©s sur la mÃªme image
- âœ… **Noms d'hÃ´te distincts** pour identification rÃ©seau
- âœ… **IDs uniques** via variable d'environnement `INSTANCE_ID`
- âœ… **Ports diffÃ©rents** exposÃ©s pour accÃ¨s direct (3000, 3004, 3003)
- âœ… **MÃªme base de donnÃ©es** PostgreSQL partagÃ©e
- âœ… **DÃ©marrage coordonnÃ©** avec health checks

### Modifications du code applicatif

**Fichier**: `app.js`

#### Identification des instances

```javascript
// Route racine
app.get('/', (req, res) => {
  res.json({
    message: 'ğŸš€ API Users - Microservice Cloud-Native',
    version: '1.0.0',
    instance: process.env.INSTANCE_ID || 'unknown',
    hostname: require('os').hostname(),
    endpoints: { ... }
  });
});

// Health check
app.get('/health', async (req, res) => {
  res.json({ 
    status: 'healthy',
    database: 'connected',
    instance: process.env.INSTANCE_ID || 'unknown',
    hostname: require('os').hostname()
  });
});
```

**BÃ©nÃ©fices** :
- âœ… Chaque rÃ©ponse identifie l'instance qui l'a traitÃ©e
- âœ… Facilite le debugging et le monitoring
- âœ… Permet de vÃ©rifier la distribution de charge

---

## âš–ï¸ 2. CONFIGURATION NGINX LOAD BALANCING âœ…

### Fichier: `nginx/gateway.conf`

#### Upstream avec 3 backends

```nginx
upstream users-backend {
    # StratÃ©gie: round-robin (par dÃ©faut)
    
    # Instance 1
    server users-service-1:3000 max_fails=3 fail_timeout=30s;
    
    # Instance 2
    server users-service-2:3000 max_fails=3 fail_timeout=30s;
    
    # Instance 3
    server users-service-3:3000 max_fails=3 fail_timeout=30s;
    
    # Connexions persistantes
    keepalive 32;
}
```

**ParamÃ¨tres de load balancing** :

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| **Algorithme** | round-robin | Distribution sÃ©quentielle (dÃ©faut) |
| **max_fails** | 3 | Ã‰checs avant de marquer le serveur down |
| **fail_timeout** | 30s | Temps avant de retester un serveur failed |
| **keepalive** | 32 | Connexions persistantes maintenues |

#### Header de tracking

```nginx
location /users {
    proxy_pass http://users-backend;
    
    add_header X-Upstream-Server $upstream_addr;  # IP:PORT du serveur
    add_header X-Served-By "API-Gateway-NGINX";
    add_header X-Service "users-service";
    
    # ... autres configurations
}
```

**Informations trackÃ©es** :
- âœ… `X-Upstream-Server` : Adresse IP et port de l'instance backend
- âœ… Permet de vÃ©rifier quelle instance a traitÃ© chaque requÃªte

### StratÃ©gies de load balancing disponibles

NGINX supporte plusieurs algorithmes (commentÃ©s dans le fichier) :

```nginx
# round-robin (dÃ©faut) : distribution sÃ©quentielle
# RequÃªte 1 â†’ Instance 1
# RequÃªte 2 â†’ Instance 2
# RequÃªte 3 â†’ Instance 3
# RequÃªte 4 â†’ Instance 1...

# least_conn : vers l'instance avec le moins de connexions actives
# ip_hash : mÃªme client toujours vers la mÃªme instance (sticky sessions)
```

---

## ğŸ§ª 3. TESTS DE RÃ‰PARTITION DE CHARGE âœ…

### Script automatisÃ©

**Fichier**: `test-load-balancing.ps1`

#### MÃ©thodologie

1. **Envoi de 20 requÃªtes** via le Gateway (`http://localhost:8080/users`)
2. **Extraction du header** `X-Upstream-Server` de chaque rÃ©ponse
3. **Mapping IP â†’ Instance** automatique
4. **Comptage des requÃªtes** par instance
5. **Analyse de la distribution**
6. **VÃ©rification directe** de chaque instance

#### RÃ©sultats des tests

**ExÃ©cution** :
```powershell
powershell -ExecutionPolicy Bypass -File test-load-balancing.ps1
```

**Output** :
```
========================================
Test de Load Balancing - Users Service
========================================

Envoi de 20 requÃªtes vers le Gateway...

Request # 1: Instance 1 | Server: 172.19.0.8:3000
Request # 2: Instance 2 | Server: 172.19.0.9:3000
Request # 3: Instance 3 | Server: 172.19.0.7:3000
Request # 4: Instance 1 | Server: 172.19.0.8:3000
Request # 5: Instance 2 | Server: 172.19.0.9:3000
...

========================================
RÃ‰SULTATS DU LOAD BALANCING
========================================

Distribution des requÃªtes par instance:

Instance 1 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7 requÃªtes (35%)
Instance 2 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 7 requÃªtes (35%)
Instance 3 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 6 requÃªtes (30%)
Instance unknown |  | 0 requÃªtes (0%)

========================================
ANALYSE
========================================

Total requÃªtes: 20
RequÃªtes distribuÃ©es: 20
RequÃªtes non distribuÃ©es: 0

Distribution attendue (round-robin):
  ~6.67 requÃªtes par instance

âœ… LOAD BALANCING : OPTIMAL
Les requÃªtes sont bien rÃ©parties entre les 3 instances
```

### Preuves de distribution

#### 1. Pattern Round-Robin visible

```
Instance 1 â†’ Instance 2 â†’ Instance 3 â†’ Instance 1 â†’ Instance 2 â†’ Instance 3...
```

âœ… **SchÃ©ma rÃ©pÃ©titif** parfaitement identifiable

#### 2. Distribution Ã©quilibrÃ©e

| Instance | RequÃªtes | Pourcentage | Attendu |
|----------|----------|-------------|---------|
| Instance 1 | 7 | 35% | ~33.3% |
| Instance 2 | 7 | 35% | ~33.3% |
| Instance 3 | 6 | 30% | ~33.3% |

âœ… **Ã‰cart minimal** (< 5% de variation)

#### 3. Toutes les instances actives

```
Instance 1 (port 3000): âœ… HEALTHY | Hostname: users-service-1
Instance 2 (port 3004): âœ… HEALTHY | Hostname: users-service-2
Instance 3 (port 3003): âœ… HEALTHY | Hostname: users-service-3
```

âœ… **100% des instances** participent au load balancing

#### 4. Adresses IPs distinctes

```
Instance 1: 172.19.0.8:3000
Instance 2: 172.19.0.9:3000
Instance 3: 172.19.0.7:3000
```

âœ… Chaque instance a sa **propre adresse IP** dans le rÃ©seau Docker

### Fichier CSV gÃ©nÃ©rÃ©

**Fichier**: `load-balancing-results.csv`

Contient pour chaque requÃªte :
- NumÃ©ro de requÃªte
- ID de l'instance
- Adresse du serveur upstream
- Code de statut HTTP

**UtilitÃ©** : Analyse dÃ©taillÃ©e, graphiques, reporting

---

## ğŸ“Š 4. MONITORING PROMETHEUS âœ…

### Configuration des targets

**Fichier**: `prometheus.yml`

```yaml
- job_name: 'users-service'
  scrape_interval: 10s
  static_configs:
    # Instance 1
    - targets: ['users-service-1:3000']
      labels:
        service: 'users-service'
        instance_id: '1'
    
    # Instance 2
    - targets: ['users-service-2:3000']
      labels:
        service: 'users-service'
        instance_id: '2'
    
    # Instance 3
    - targets: ['users-service-3:3000']
      labels:
        service: 'users-service'
        instance_id: '3'
```

**BÃ©nÃ©fices** :
- âœ… **MÃ©triques sÃ©parÃ©es** pour chaque instance
- âœ… **Label `instance_id`** pour filtrage
- âœ… **Monitoring individuel** des performances
- âœ… **DÃ©tection de problÃ¨mes** sur une instance spÃ©cifique

### RequÃªtes PromQL utiles

```promql
# RequÃªtes totales par instance
sum(rate(http_requests_total[1m])) by (instance_id)

# Latence par instance
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket[5m])
) by (instance_id)

# Instances UP
up{job="users-service"}

# Compter les instances actives
count(up{job="users-service"} == 1)
```

---

## ğŸ—ï¸ ARCHITECTURE FINALE

### SchÃ©ma CompletNGINX Load Balancer (8080)
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬
    â–¼       â–¼       â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚User â”‚ â”‚User â”‚ â”‚User â”‚   â”‚Products  â”‚
â”‚Svc 1â”‚ â”‚Svc 2â”‚ â”‚Svc 3â”‚   â”‚Service   â”‚
â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
   â”‚       â”‚       â”‚            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚Users DB â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9 conteneurs actifs

| Conteneur | RÃ´le | Port | Statut |
|-----------|------|------|--------|
| **api-gateway** | NGINX Load Balancer | 8080 | âœ… UP |
| **users-service-1** | Instance 1 | 3000 | âœ… UP |
| **users-service-2** | Instance 2 | 3004 | âœ… UP |
| **users-service-3** | Instance 3 | 3003 | âœ… UP |
| **products-service** | Products API | 3002 | âœ… UP |
| **users-postgres** | PostgreSQL Users | 5432 | âœ… HEALTHY |
| **products-postgres** | PostgreSQL Products | 5433 | âœ… HEALTHY |
| **prometheus** | MÃ©triques | 9090 | âœ… UP |
| **grafana** | Dashboards | 3001 | âœ… UP |

---

## ğŸ¯ VALIDATION DES OBJECTIFS

| Objectif | Livrable | Statut | Preuve |
|----------|----------|--------|--------|
| **Lancer 3 instances** | users-service-1,2,3 | âœ… | `docker-compose ps` |
| **Config NGINX LB** | gateway.conf upstream | âœ… | 3 servers configurÃ©s |
| **Test rÃ©partition** | Script PowerShell | âœ… | Distribution 35/35/30% |
| **Preuve distribution** | CSV + logs | âœ… | 20 requÃªtes analysÃ©es |
| **Round-robin** | Pattern visible | âœ… | SÃ©quence 1-2-3-1-2-3 |
| **Toutes instances actives** | Health checks | âœ… | 3/3 healthy |

**TOUS LES OBJECTIFS SONT ATTEINTS** âœ…

---

## ğŸ“ COMMANDES DE VÃ‰RIFICATION

### Voir les conteneurs

```powershell
docker-compose ps
```

**Attendu** : 9 services UP (dont 3 users-service)

### Tester le load balancing

```powershell
powershell -ExecutionPolicy Bypass -File test-load-balancing.ps1
```

**Attendu** : Distribution ~33% par instance

### AccÃ¨s direct aux instances

```powershell
# Instance 1
Invoke-RestMethod http://localhost:3000/health

# Instance 2
Invoke-RestMethod http://localhost:3004/health

# Instance 3
Invoke-RestMethod http://localhost:3003/health
```

**Attendu** : Chaque instance retourne son hostname

### Via le Gateway (load balanced)

```powershell
# 10 requÃªtes pour voir la rotation
for ($i=1; $i -le 10; $i++) {
    $response = Invoke-WebRequest http://localhost:8080/users
    Write-Host "Request $i : " -NoNewline
    Write-Host $response.Headers['X-Upstream-Server']
}
```

**Attendu** : Rotation visible des adresses IP

---

## ğŸ” TESTS DE DÃ‰FAILLANCE

### Simuler une panne d'instance

```powershell
# ArrÃªter instance 2
docker stop users-service-2

# Tester (devrait rÃ©partir sur instances 1 et 3 uniquement)
powershell -ExecutionPolicy Bypass -File test-load-balancing.ps1

# RedÃ©marrer
docker start users-service-2
```

**RÃ©sultat attendu** :
- NGINX dÃ©tecte l'instance down
- RÃ©partit sur les 2 instances restantes
- RÃ©cupÃ©ration automatique au redÃ©marrage

---

## ğŸ“ˆ BÃ‰NÃ‰FICES DE LA SCALABILITÃ‰ HORIZONTALE

### 1. Performance

- âœ… **3x plus de capacitÃ©** de traitement
- âœ… **RÃ©duction de la latence** (charge distribuÃ©e)
- âœ… **ParallÃ©lisation** des requÃªtes

### 2. DisponibilitÃ©

- âœ… **High Availability** : Une instance peut tomber sans interruption
- âœ… **Zero Downtime Deployment** possible
- âœ… **Failover automatique** via NGINX

### 3. ScalabilitÃ©

- âœ… **Scale OUT facile** : Ajouter des instances Ã  la demande
- âœ… **Scale IN** : RÃ©duire si charge faible
- âœ… **Auto-scaling** possible (Kubernetes, Docker Swarm)

### 4. CoÃ»t

- âœ… **Pay-per-use** : Adapter les ressources Ã  la charge
- âœ… **Optimisation** : Pas de sur-provisioning

---

## ğŸ”„ Ã‰VOLUTION FUTURE

### Scaling dynamique

```yaml
users-service:
  deploy:
    replicas: 3
    update_config:
      parallelism: 1
      delay: 10s
    restart_policy:
      condition: on-failure
```

### Health checks avancÃ©s

```nginx
upstream users-backend {
    server users-service-1:3000 max_fails=2 fail_timeout=10s;
    server users-service-2:3000 max_fails=2 fail_timeout=10s;
    server users-service-3:3000 max_fails=2 fail_timeout=10s backup;  # Backup
    
    # Active health checks (NGINX Plus)
    # health_check interval=5s fails=3 passes=2;
}
```

### Load balancing avancÃ©

```nginx
# Weighted round-robin
server users-service-1:3000 weight=3;  # 3x plus de requÃªtes
server users-service-2:3000 weight=2;
server users-service-3:3000 weight=1;

# Least connections
least_conn;

# IP Hash (sticky sessions)
ip_hash;
```

---

## âœ¨ CONCLUSION

Le Module 4 dÃ©montre avec succÃ¨s la **scalabilitÃ© horizontale** de l'architecture microservices.

**Points forts** :
- âœ… **3 instances** dÃ©ployÃ©es et fonctionnelles
- âœ… **Load balancing NGINX** configurÃ© et testÃ©
- âœ… **Distribution optimale** des requÃªtes (round-robin)
- âœ… **Monitoring** de chaque instance via Prometheus
- âœ… **Preuves tangibles** via script de test et CSV

**MÃ©triques** :
- 9 conteneurs orchestrÃ©s
- 3 instances users-service en load balancing
- Distribution: 35% / 35% / 30% (optimal)
- 100% des requÃªtes distribuÃ©es correctement

**Date de rÃ©alisation** : 5 dÃ©cembre 2025  
**Technologies** : Docker Compose, NGINX, PowerShell  
**Status** : âœ… **MODULE 4 COMPLÃ‰TÃ‰**

---

**ğŸ‰ SCALABILITÃ‰ HORIZONTALE OPÃ‰RATIONNELLE !**
